{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV8 Face Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import wandb\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov8n-face.pt already exists, skipping download.\n",
      "yolov8l-face.pt already exists, skipping download.\n",
      "yolov8m-face.pt already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Download the checkpoints for YoloV8\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Define the folder and file details\n",
    "folder = \"checkpoints\"\n",
    "checkpoint_details = [\"yolov8n-face.pt\", \"yolov8l-face.pt\", \"yolov8m-face.pt\"]\n",
    "os.makedirs(folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "# URLs corresponding to the checkpoints\n",
    "urls = [\n",
    "    \"https://github.com/akanametov/yolov8-face/releases/download/v0.0.0/yolov8n-face.pt\",\n",
    "    \"https://github.com/akanametov/yolov8-face/releases/download/v0.0.0/yolov8l-face.pt\",\n",
    "    \"https://github.com/akanametov/yolov8-face/releases/download/v0.0.0/yolov8m-face.pt\",\n",
    "]\n",
    "\n",
    "# Check and download the files\n",
    "for url in urls:\n",
    "    filename = os.path.basename(url)\n",
    "    destination = os.path.join(folder, filename)\n",
    "    \n",
    "    if not os.path.exists(destination):  # Check if file already exists\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, destination)\n",
    "        print(f\"Downloaded to {destination}\")\n",
    "    else:\n",
    "        print(f\"{filename} already exists, skipping download.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from typing import Any\n",
    "\n",
    "def validate_coco_yaml(yaml_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validates the structure of a COCO-style YAML configuration.\n",
    "\n",
    "    Args:\n",
    "        yaml_path (str): Path to the YAML file to validate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the YAML is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    required_fields = {\n",
    "        \"path\": str,\n",
    "        \"train\": str,\n",
    "        \"val\": str,\n",
    "        \"names\": dict\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Load YAML file\n",
    "        with open(yaml_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        \n",
    "        # Validate top-level fields\n",
    "        for field, field_type in required_fields.items():\n",
    "            if field not in config:\n",
    "                print(f\"Error: Missing required field '{field}'.\")\n",
    "                return False\n",
    "            if not isinstance(config[field], field_type):\n",
    "                print(f\"Error: Field '{field}' should be of type {field_type.__name__}.\")\n",
    "                return False\n",
    "        \n",
    "        # Validate 'names' dictionary\n",
    "        names = config[\"names\"]\n",
    "        if not all(isinstance(key, int) and isinstance(value, str) for key, value in names.items()):\n",
    "            print(\"Error: 'names' should be a dictionary with integer keys and string values.\")\n",
    "            return False\n",
    "        \n",
    "        # Optional fields\n",
    "        if \"test\" in config and config[\"test\"] is not None:\n",
    "            if not isinstance(config[\"test\"], str):\n",
    "                print(\"Error: 'test' should be of type str if provided.\")\n",
    "                return False\n",
    "\n",
    "        print(\"YAML is valid.\")\n",
    "        return True\n",
    "    \n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Error parsing YAML file: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML is valid.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "yaml_path = \"coco8.yaml\"\n",
    "ok = validate_coco_yaml(yaml_path)\n",
    "print(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained model used to detect faces\n",
    "model = YOLO(f\"{folder}/yolov8m-face.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.61  Python-3.11.9 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=checkpoints/yolov8m-face.pt, data=coco8.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=exp, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\soura\\Desktop\\my-sdk\\runs\\detect\\exp\n",
      "\n",
      "Dataset 'coco8.yaml' images not found , missing path 'C:\\Users\\soura\\Desktop\\datasets\\coco128\\images\\train2017'\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to 'C:\\Users\\soura\\Desktop\\datasets\\coco128.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.66M/6.66M [00:00<00:00, 11.2MB/s]\n",
      "Unzipping C:\\Users\\soura\\Desktop\\datasets\\coco128.zip to C:\\Users\\soura\\Desktop\\datasets\\coco128...: 100%|██████████| 263/263 [00:00<00:00, 1396.94file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success  (3.7s), saved to \u001b[1mC:\\Users\\soura\\Desktop\\datasets\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\soura\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 3.76MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=1 with nc=80\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.head.Detect           [80, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25,902,640 parameters, 25,902,624 gradients, 79.3 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\soura\\Desktop\\datasets\\coco128\\labels\\train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<00:00, 195.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\soura\\Desktop\\datasets\\coco128\\labels\\train2017.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\soura\\Desktop\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\soura\\Desktop\\my-sdk\\runs\\detect\\exp\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\soura\\Desktop\\my-sdk\\runs\\detect\\exp\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=1,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    name=\"exp\",\n",
    "    exist_ok=False,\n",
    "    plots=True,\n",
    "    save=True,\n",
    "    resume=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
